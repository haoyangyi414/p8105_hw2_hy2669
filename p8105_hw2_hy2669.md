p8105\_hw2\_hy2669
================
Haoyang Yi
2020/9/27

``` r
library(tidyverse)
```

    ## -- Attaching packages -------------------------------------------------------------- tidyverse 1.3.0 --

    ## √ ggplot2 3.3.2     √ purrr   0.3.4
    ## √ tibble  3.0.3     √ dplyr   1.0.2
    ## √ tidyr   1.1.2     √ stringr 1.4.0
    ## √ readr   1.3.1     √ forcats 0.5.0

    ## -- Conflicts ----------------------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

``` r
trashwheel = read_xlsx('./data/problem1/Trash-Wheel-Collection-Totals-8-6-19.xlsx',
                      sheet = 'Mr. Trash Wheel',
                      range = cell_cols("A:N")) 
trashwheel = janitor::clean_names(trashwheel) %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = round(sports_balls)) %>%
  mutate(sports_balls = as.integer(sports_balls)) 
```

    ## Warning in FUN(X[[i]], ...): strings not representable in native encoding will
    ## be translated to UTF-8

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C4>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00D6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E4>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00F6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00DF>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00D8>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00F8>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C5>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E5>' to native encoding

There are 14 observations in trashwheel dataset \#\#\#\# read
precipitation of 2017 and 2018 separately

``` r
precip_2018 = read_xlsx('./data/problem1/Trash-Wheel-Collection-Totals-8-6-19.xlsx',
                      sheet = '2018 Precipitation',skip = 1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = read_xlsx('./data/problem1/Trash-Wheel-Collection-Totals-8-6-19.xlsx',
                      sheet ='2017 Precipitation',skip = 1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
# combine annual precipitation
month_df = tibble(month = 1:12,
                month_name = month.name)
precip_df = bind_rows(precip_2018,precip_2017)
precipmerge_df=left_join(precip_df,month_df,by ='month') 
```

There are 4 observations in precipitation dataset for 2017 and
2018.There are 14 observations in Mr.Trash Wheel sheet dataset. The
total precipitation in 2018 is 70.33. The median number of sports balls
in a dumpster in 2017 is 8.

## Problem 2

``` r
nyc_transit_df = read_csv('./data/problem2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv')  
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
  nyc_transit_df = janitor::clean_names(nyc_transit_df) %>% 
  select(line,station_name,station_latitude,station_longitude,
         route1:route11,entry,vending,entrance_type, ada) %>% # select columns
  mutate(entry = recode(entry,"YES"="TRUE","NO"="FALSE")) %>%
  mutate(entry = as.logical(entry)) # change entry from character yes/no to logical TRUE/FALSE
  head(nyc_transit_df)
```

    ## # A tibble: 6 x 19
    ##   line  station_name station_latitude station_longitu~ route1 route2 route3
    ##   <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
    ## 1 4 Av~ 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ## 2 4 Av~ 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ## 3 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
    ## 4 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
    ## 5 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
    ## 6 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ## # ... with 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>,
    ## #   route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>,
    ## #   entry <lgl>, vending <chr>, entrance_type <chr>, ada <lgl>

This dataset contains information of stations including
names,locations,routes they serve,entrance type, ADA compliance,entry
and vending status (line, station\_name, station\_latitude,
station\_longitude, route1, route2, route3, route4, route5, route6,
route7, route8, route9, route10, route11, entry, vending,
entrance\_type, ada). Data cleaning steps: read the data-clean the
name-select columns to retain-convert the entry variable from character
to logical.The resulting dataset has 19 columns and 1868 rows.These data
are not tidy since there are too many routes columns from 1 to 11,making
the dataset too wide, and route1:route7 are character variables while
route8:route11 are numeric variables.

``` r
  nyc_station<-distinct(nyc_transit_df,station_name,line,.keep_all=TRUE) # get distinct stations based on name and line.
```

There are 465 distinct stations. There are 84 ADA compliant stations.

``` r
  nyc = filter(nyc_transit_df,vending =='NO') # get stations without vending 
  nycentry = filter(nyc,entry == TRUE) # get stations without vending allow entrance
```

The proportion = number of stations without vending allow entrance/
total number of stations without vending = 0.3770492

``` r
nyc_tidy_df = nyc_transit_df %>%
  mutate_at(vars(route1:route11),as.character) %>%
  pivot_longer(route1:route11,names_to ='route_name',names_prefix ='route',
               values_to ='route_number') %>%
  drop_na(route_number) 
  head(nyc_tidy_df) # Reformat the data so that the route number and route name are distinct variables
```

    ## # A tibble: 6 x 10
    ##   line  station_name station_latitude station_longitu~ entry vending
    ##   <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ## 1 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ## 2 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ## 3 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ## 4 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ## 5 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ## 6 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ## # ... with 4 more variables: entrance_type <chr>, ada <lgl>, route_name <chr>,
    ## #   route_number <chr>

``` r
  a_df<-filter(nyc_tidy_df,route_number =='A')
```

There are 60 distinct stations serve the A train

``` r
  ada_df = filter(a_df,ada =='TRUE')
```

Of the stations that serve the A train, 17 are ADA compliant

## Problem 3

``` r
pols_month_df = read_csv('./data/problem3/pols-month.csv') 
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
snp_df = read_csv('./data/problem3/snp.csv')
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
unemployment_df = read_csv('./data/problem3/unemployment.csv')
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
  pols_month_df = separate(pols_month_df,mon,into = c('year','month','day')) %>%
  mutate(month = month.abb[as.factor(month)]) %>% # replace month number with month name
  mutate(president = recode(prez_gop,'0'='dem','1'='gop','2'='abnormal')) %>% 
  mutate(year = as.integer(year)) %>%  # convert year variable to integer 
  select(-prez_dem,-prez_gop,-day) # separate mon into year month and day. 
# Create president variable to show the party that the president belongs. remove prez_dem, prez_gop and day variables
  snp_df = separate(snp_df,date,into=c('month','day','year')) %>%
  arrange(year,month) %>% # arrange according to year and month
  mutate(month = month.abb[as.factor(month)]) %>% 
  mutate(year = as.integer(year)) %>% 
  select(year,month,close)  # clean and tidy the data in snp.csv,organize columns.
  unemployment_df = pivot_longer(unemployment_df,Jan:Dec,names_to = 'month',
                                 values_to = 'rate of unemployment') %>%
  rename(year = Year) # switch the unemployment dataset to 'long'
  # rename the Year variable to year according to name of variable in pols_month and snp datasets.
two_df = left_join(pols_month_df,snp_df) 
```

    ## Joining, by = c("year", "month")

``` r
final_df = left_join(two_df,unemployment_df) # first, merge snp into pols, then merge unemployment in to the previous result.
```

    ## Joining, by = c("year", "month")

The pols dataset contains numbers of republican and democratic national
politicians on associated date.The snp dataset contains closing values
fo S\&P stock index on the associated date. The unemployment dataset
contains percentage of unemployment in each month of the associated
year. The dimension of the resulting dataset is 822 rows and 11 columns.
The range of years is 1947, 2015. Key variables are president(republican
or democratic), numbers of republican and democratic governors,senators
and representatives, closing values of S\&P stock index, precentage of
unemployment (year, month, gov\_gop, sen\_gop, rep\_gop, gov\_dem,
sen\_dem, rep\_dem, president, close, rate of unemployment)
